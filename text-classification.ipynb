{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## (a) Install and import libraries","metadata":{"id":"ShSxAMlixxrm"}},{"cell_type":"code","source":"!pip install datasets evaluate accelerate\n!pip install causal - conv1d >=1.1.0\n!pip install mamba - ssm\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xBw0Tafvsid","outputId":"05cf6026-e7d6-4126-b0c0-ff33c1bb9903","execution":{"iopub.status.busy":"2024-03-26T19:43:24.412397Z","iopub.execute_input":"2024-03-26T19:43:24.413399Z","iopub.status.idle":"2024-03-26T19:43:47.530896Z","shell.execute_reply.started":"2024-03-26T19:43:24.413349Z","shell.execute_reply":"2024-03-26T19:43:47.529863Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.3.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2+cpu)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n\u001b[31mERROR: Invalid requirement: '-'\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Invalid requirement: '-'\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login #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\nnotebook_login ()","metadata":{"id":"Pl4D5811vx8q","execution":{"iopub.status.busy":"2024-03-26T19:43:47.533578Z","iopub.execute_input":"2024-03-26T19:43:47.533963Z","iopub.status.idle":"2024-03-26T19:43:47.906408Z","shell.execute_reply.started":"2024-03-26T19:43:47.533924Z","shell.execute_reply":"2024-03-26T19:43:47.904923Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ed33e807ef84294a0e0dd1ba2914a38"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install mamba_ssm","metadata":{"id":"cCmzi4s7xEWP","execution":{"iopub.status.busy":"2024-03-26T19:47:37.326346Z","iopub.execute_input":"2024-03-26T19:47:37.326837Z","iopub.status.idle":"2024-03-26T19:47:44.216656Z","shell.execute_reply.started":"2024-03-26T19:47:37.326804Z","shell.execute_reply":"2024-03-26T19:47:44.215206Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting mamba_ssm\n  Using cached mamba_ssm-1.2.0.post1.tar.gz (34 kB)\n  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[13 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m /tmp/pip-install-_ede7dgy/mamba-ssm_37617d63613249c7bec56124c80304aa/setup.py:78: UserWarning: mamba_ssm was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n  \u001b[31m   \u001b[0m   warnings.warn(\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-_ede7dgy/mamba-ssm_37617d63613249c7bec56124c80304aa/setup.py\", line 112, in <module>\n  \u001b[31m   \u001b[0m     if bare_metal_version >= Version(\"11.8\"):\n  \u001b[31m   \u001b[0m NameError: name 'bare_metal_version' is not defined\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m torch.__version__  = 2.1.2+cpu\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25h","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\nimport json\nimport torch\nimport torch.nn as nn\nfrom collections import namedtuple\nfrom dataclasses import dataclass, field, asdict\nfrom mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\nfrom mamba_ssm.utils.hf import load_config_hf, load_state_dict_hf\n\nimport evaluate\nimport numpy as np\nfrom datasets import load_dataset\nfrom transformers import Trainer\nfrom transformers import AutoTokenizer, TrainingArguments\n","metadata":{"id":"bsHYY5AQw80A","execution":{"iopub.status.busy":"2024-03-26T19:46:17.465266Z","iopub.execute_input":"2024-03-26T19:46:17.465758Z","iopub.status.idle":"2024-03-26T19:46:17.525101Z","shell.execute_reply.started":"2024-03-26T19:46:17.465724Z","shell.execute_reply":"2024-03-26T19:46:17.523077Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass, field, asdict\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixer_seq_simple\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MambaLMHeadModel\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_config_hf, load_state_dict_hf\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluate\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mamba_ssm'"],"ename":"ModuleNotFoundError","evalue":"No module named 'mamba_ssm'","output_type":"error"}]},{"cell_type":"markdown","source":"## (b) Download dataset:\n","metadata":{"id":"PTqDPIhRxW0Y"}},{"cell_type":"code","source":"# Tải bộ dataset\nimdb = load_dataset (\" imdb \")\n","metadata":{"id":"5ifcKwdGxAL6","execution":{"iopub.status.busy":"2024-03-26T19:43:59.836523Z","iopub.status.idle":"2024-03-26T19:43:59.837030Z","shell.execute_reply.started":"2024-03-26T19:43:59.836806Z","shell.execute_reply":"2024-03-26T19:43:59.836827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (c) Build Custom Mamba Model","metadata":{"id":"6k7k-SRD0WoE"}},{"cell_type":"code","source":"# Config class của Mamba\nclass MambaConfig:\n    d_model: int = 2560\n    n_layer: int = 64\n    vocab_size: int = 50277\n    ssm_cfg: dict = field(default_factory=dict)\n    rms_norm: bool = True\n    residual_in_fp32: bool = True\n    fused_add_norm: bool = True\n    pad_vocab_size_multiple: int = 8\n\n    def to_json_string(self):\n        return json.dumps(asdict(self))\n\n    def to_dict(self):\n        return asdict(self)\n","metadata":{"id":"bVKETZ2RyDp3","execution":{"iopub.status.busy":"2024-03-26T19:43:59.838925Z","iopub.status.idle":"2024-03-26T19:43:59.839389Z","shell.execute_reply.started":"2024-03-26T19:43:59.839184Z","shell.execute_reply":"2024-03-26T19:43:59.839202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Định nghĩa class head để phân loại\nclass MambaClassificationHead(nn.Module):\n    def __init__(self, d_model, num_classes, **kwargs):\n        super(MambaClassificationHead, self).__init__()\n        # Sử dụng một lớp tuyến tính để thực hiện phân loại dựa trên\n        # đầu vào có kích thước d_model và num_classes cần phân loại.\n        self.classification_head = nn.Linear(d_model, num_classes, **kwargs)\n\n    def forward(self, hidden_states):\n        return self.classification_head(hidden_states)\n","metadata":{"id":"mhatxwvvyKAp","execution":{"iopub.status.busy":"2024-03-26T19:43:59.840936Z","iopub.status.idle":"2024-03-26T19:43:59.841398Z","shell.execute_reply.started":"2024-03-26T19:43:59.841196Z","shell.execute_reply":"2024-03-26T19:43:59.841213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MambaTextClassification(MambaLMHeadModel):\n    def __init__(\n        self,\n        config: MambaConfig,\n        initializer_cfg=None,\n        device=None,\n        dtype=None,\n    ) -> None:\n        super().__init__(config, initializer_cfg, device, dtype)\n\n        # Tạo một đầu phân loại sử dụng MambaClassificationHead với\n        # kích thước đầu vào là d_model và số lớp là 2.\n        self.classification_head = MambaClassificationHead(\n            d_model=config.d_model, num_classes=2\n        )\n\n        del self.lm_head\n\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        # Truyền input_ids qua model gốc để nhận hidden_states.\n        hidden_states = self.backbone(input_ids)\n\n        # Lấy trung bình của hidden_states theo chiều thứ 2 để tạo\n        # ra [CLS] feature đại diện\n        mean_hidden_states = hidden_states.mean(dim=1)\n\n        # Đưa mean_hidden_states qua đầu phân loại để nhận logits.\n        logits = self.classification_head(mean_hidden_states)\n\n        if labels is None:\n            ClassificationOutput = namedtuple(\"ClassificationOutput\", [\"logits\"])\n            return ClassificationOutput(logits=logits)\n        else:\n            ClassificationOutput = namedtuple(\"ClassificationOutput\", [\"loss\", \"logits\"])\n\n            # Sử dụng hàm mất mát CrossEntropyLoss để tính loss.\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits, labels)\n\n            return ClassificationOutput(loss=loss, logits=logits)\n\n    def predict(self, text, tokenizer, id2label=None):\n        input_ids = torch.tensor(tokenizer(text)['input_ids'], device='cuda')[None]\n        with torch.no_grad():\n            logits = self.forward(input_ids).logits[0]\n            label = np.argmax(logits.cpu().numpy())\n\n            if id2label is not None:\n                return id2label[label]\n            else:\n                return label\n\n    @classmethod\n    def from_pretrained(cls, pretrained_model_name, device=None, dtype=None, **kwargs):\n        # Tải cấu hình từ model đã được train trước đó.\n        config_data = load_config_hf(pretrained_model_name)\n        config = MambaConfig(**config_data)\n\n        # Khởi tạo model từ cấu hình và chuyển nó đến thiết bị và kiểu dữ liệu mong muốn.\n        model = cls(config, device=device, dtype=dtype, **kwargs)\n\n        # Tải trạng thái model đã được train trước đó.\n        model_state_dict = load_state_dict_hf(pretrained_model_name, device=device, dtype=dtype)\n        model.load_state_dict(model_state_dict, strict=False)\n\n        # In ra các tham số embedding mới được khởi tạo.\n        print(\"Newly initialized embedding:\", set(model.state_dict().keys()) - set(model_state_dict.keys()))\n        return model\n","metadata":{"id":"1ci--rxHzIG2","execution":{"iopub.status.busy":"2024-03-26T19:43:59.843884Z","iopub.status.idle":"2024-03-26T19:43:59.844408Z","shell.execute_reply.started":"2024-03-26T19:43:59.844180Z","shell.execute_reply":"2024-03-26T19:43:59.844200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Tải model Mamba từ model đã được train trước đó.\nmodel = MambaTextClassification . from_pretrained (\"state - spaces /mamba-130 m\")\nmodel . to (\" cuda \")\n# Tải tokenizer của model Mamba từ model gpt -neox -20 b.\ntokenizer = AutoTokenizer . from_pretrained (\" EleutherAI /gpt -neox -20 b\")\n# Đặt id của token pad bằng id của token eos trong tokenizer\ntokenizer . pad_token_id = tokenizer . eos_token_id","metadata":{"id":"PQjfR2QuynQB","execution":{"iopub.status.busy":"2024-03-26T19:43:59.845925Z","iopub.status.idle":"2024-03-26T19:43:59.846405Z","shell.execute_reply.started":"2024-03-26T19:43:59.846192Z","shell.execute_reply":"2024-03-26T19:43:59.846211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (d) Preprocess dataset: Trong phần này ta sẽ tiến hành tokenize dataset cho tập train và tập test.\n Vì số lượng sample của tập test khá lớn nên để thuận tiện cho quá trình train ta sẽ lấy\nra 1 phần nhỏ của tập test để đánh giá model.","metadata":{"id":"lzIuZP4QxUxg"}},{"cell_type":"code","source":"# Tạo chức năng tiền xử lý để mã hóa văn bản và cắt bớt các chuỗi không\n# dài hơn độ dài đầu vào tối đa của mã thông báo\ndef preprocess_function(examples):\n    samples = tokenizer(examples[\"text\"], truncation=True)\n    # Không cần attention_mask\n    # Cụ thể hơn về token masking của mamba có thể tham khảo: https://\n    # github.com/state-spaces/mamba/issues/49\n    samples.pop('attention_mask')\n    return samples\n\n# Thực hiện mã hóa văn bản\ntokenized_imdb = imdb.map(preprocess_function, batched=True)\n\n# Set seed cho hàm random\nrandom.seed(42)\n\n# Tạo tập train và test\ntrain_dataset = tokenized_imdb[\"train\"]\ntest_dataset = tokenized_imdb[\"test\"]\n\n# Tạo tập evaluation để đánh giá trong lúc train\n# Do số lượng tập test lớn nên chỉ lấy mẫu 1% tập dữ liệu test để đánh giá\ntotal_samples = len(test_dataset)\neval_samples = int(0.1 * total_samples)\neval_indices = random.sample(range(total_samples), eval_samples)\n","metadata":{"id":"QDEsLDHEzxNU","execution":{"iopub.status.busy":"2024-03-26T19:43:59.847749Z","iopub.status.idle":"2024-03-26T19:43:59.848191Z","shell.execute_reply.started":"2024-03-26T19:43:59.847980Z","shell.execute_reply":"2024-03-26T19:43:59.847997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (e) Evaluation metric:\nĐể đánh giá performance của model ta sẽ sử dụng metric accuracy từ\nthư viện evaluate:","metadata":{"id":"ZtbpDlU0PtKt"}},{"cell_type":"code","source":"# Tải module \" accuracy \" từ thư viện evaluate .\naccuracy = evaluate . load (\"accuracy\")\n# Định nghĩa hàm compute_metrics để tính các độ đo hiệu suất ( metrics ) cho việc đánh giá model .\ndef compute_metrics ( eval_pred ):\n  predictions , labels = eval_pred\n  # Lấy chỉ số của lớp có xác suất cao nhất trong predictions.\n  predictions = np.argmax(predictions, axis=1)\n\n  # Sử dụng module \"accuracy\" để tính độ chính xác dựa trên predictions và labels.\n  return accuracy.compute(predictions=predictions, references=labels)\n","metadata":{"id":"TInLoeZnyzmU","execution":{"iopub.status.busy":"2024-03-26T19:43:59.849565Z","iopub.status.idle":"2024-03-26T19:43:59.849999Z","shell.execute_reply.started":"2024-03-26T19:43:59.849782Z","shell.execute_reply":"2024-03-26T19:43:59.849809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (f) Train model:\nSau khi đã chuẩn bị xong dataset, ta sẽ tiến hành setup một số tham số trong\nquá trình train và tiến hành train model.","metadata":{"id":"dOfWyuXu0fS1"}},{"cell_type":"code","source":"# Định nghĩa tên project để log thông tin quá trình train trên wandb\n# os.environ[\"WANDB_PROJECT\"] = \"mamba_tutorial\"\n\n# Định nghĩa các tham số train trong class TrainingArguments.\n# Cụ thể hơn về các tham số hỗ trợ có thể tham khảo: https://\n# huggingface.co/docs/transformers/main_classes/trainer\ntraining_args = TrainingArguments(\n    output_dir=\"mamba_text_classification\", # Tên folder output\n    learning_rate=5e-5,\n    per_device_train_batch_size=4, # Số lượng train sample trên mỗi device\n    per_device_eval_batch_size=16, # Số lượng eval sample trên mỗi device\n    num_train_epochs=1, # Số epoch train\n    warmup_ratio=0.01, # Tỉ lệ tăng dần lr trong giai đoạn warmup\n    lr_scheduler_type=\"cosine\", # Loại scheduler để giảm lr\n    report_to=\"none\", # \"wandb\" nếu muốn log kết quả\n    evaluation_strategy=\"steps\", # Xác định metric đánh giá sau mỗi số bước\n    eval_steps=0.1, # Số bước giữa các đợt đánh giá\n    save_strategy=\"steps\", # Xác định khi nào lưu checkpoint\n    save_steps=0.1, # Số bước giữa các lần lưu checkpoint\n    logging_strategy=\"steps\", # Xác định khi nào in thông tin log\n    logging_steps=1, # Số bước giữa các lần in thông tin log\n    push_to_hub=True, # Đẩy kết quả lên Hub\n    load_best_model_at_end=True, # Load model có kết quả evaluation tốt nhất trong quá trình train\n)\n","metadata":{"id":"F-PWUSqk0NdC","execution":{"iopub.status.busy":"2024-03-26T19:43:59.851182Z","iopub.status.idle":"2024-03-26T19:43:59.851584Z","shell.execute_reply.started":"2024-03-26T19:43:59.851392Z","shell.execute_reply":"2024-03-26T19:43:59.851408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Định nghĩa một class MambaTrainer kế thừa từ class Trainer.\nclass MambaTrainer(Trainer):\n\n    # Định nghĩa hàm compute_loss để tính toán hàm mất mát trong quá trình train.\n    def compute_loss(self, model, inputs, return_outputs=False):\n        # Lấy giá trị input_ids và labels từ inputs.\n        input_ids = inputs.pop(\"input_ids\")\n        labels = inputs.pop('labels')\n\n        # Gọi hàm forward của model với input_ids và labels để nhận các kết quả.\n        outputs = model(input_ids=input_ids, labels=labels)\n\n        # Lấy giá trị loss từ kết quả của model.\n        loss = outputs.loss\n\n        # Trả về cả loss và outputs nếu return_outputs là True, ngược lại chỉ trả về loss.\n        return (loss, outputs) if return_outputs else loss\n\n    # Định nghĩa hàm save_model để lưu model trong quá trình train.\n    def save_model(self, output_dir=None, _internal_call=False):\n        # Kiểm tra nếu thư mục lưu trữ không được chỉ định, sử dụng thư mục mặc định từ đối số 'args'.\n        if output_dir is None:\n            output_dir = self.args.output_dir\n\n        # Nếu thư mục đầu ra không tồn tại, tạo mới nó.\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n\n        # Lưu trạng thái của model PyTorch vào file 'pytorch_model.bin' trong thư mục đầu ra.\n        torch.save(self.model.state_dict(), f\"{output_dir}/pytorch_model.bin\")\n\n        # Lưu trạng thái của tokenizer vào thư mục đầu ra.\n        self.tokenizer.save_pretrained(output_dir)\n\n        # Lưu cấu hình của model vào file 'config.json' trong thư mục đầu ra.\n        with open(f'{output_dir}/config.json', 'w') as f:\n            json.dump(self.model.config.to_dict(), f)\n","metadata":{"id":"0fTpNNEWP56W","execution":{"iopub.status.busy":"2024-03-26T19:43:59.853653Z","iopub.status.idle":"2024-03-26T19:43:59.854301Z","shell.execute_reply.started":"2024-03-26T19:43:59.853976Z","shell.execute_reply":"2024-03-26T19:43:59.854001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Khởi tạo class MambaTrainer để thực hiện quá trình train của model.\ntrainer = MambaTrainer(\n    model=model,  # Model cần train\n    train_dataset=train_dataset,  # Dữ liệu train\n    eval_dataset=eval_dataset,  # Dữ liệu đánh giá\n    tokenizer=tokenizer,  # Tokenizer sử dụng để mã hóa dữ liệu\n    args=training_args,  # Các tham số train đã được định nghĩa trước đó\n    compute_metrics=compute_metrics  # Hàm tính các độ đo hiệu suất (metrics) cho đánh giá\n)\n\n# Bắt đầu quá trình train bằng cách gọi hàm train() trên class trainer.\ntrainer.train()\n","metadata":{"id":"fzON2or2QpnD","execution":{"iopub.status.busy":"2024-03-26T19:43:59.856042Z","iopub.status.idle":"2024-03-26T19:43:59.856634Z","shell.execute_reply.started":"2024-03-26T19:43:59.856350Z","shell.execute_reply":"2024-03-26T19:43:59.856374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Đẩy model lên huggingface hub\ntrainer . push_to_hub ( commit_message =\" Training complete \")","metadata":{"id":"waSi63OhQpVX","execution":{"iopub.status.busy":"2024-03-26T19:43:59.858169Z","iopub.status.idle":"2024-03-26T19:43:59.858597Z","shell.execute_reply.started":"2024-03-26T19:43:59.858395Z","shell.execute_reply":"2024-03-26T19:43:59.858412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (g) Run Testing:\nSau khi đã hoàn tất quá trình train, ta sẽ đánh giá model trên tập test và in\nra kết quả đánh giá của model:\n","metadata":{"id":"u5pHED8d0mQC"}},{"cell_type":"code","source":"# Thực hiện dự đoán trên tập dữ liệu validation\noutputs = trainer . predict (test_dataset)\nprint (outputs.metrics)","metadata":{"id":"eWAF1GqnQ0IQ","execution":{"iopub.status.busy":"2024-03-26T19:43:59.859680Z","iopub.status.idle":"2024-03-26T19:43:59.860098Z","shell.execute_reply.started":"2024-03-26T19:43:59.859886Z","shell.execute_reply":"2024-03-26T19:43:59.859902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (h) Load and inference model from Hub:\n Ở phần trước, sau khi ta đưa model lên Hugging-face Hub, nếu muốn inference model ta có thể gọi hàm from_pretrained của model Mamba ta\nđã định nghĩa ở trước để load pretrain model. Sau đó ta sẽ truyền văn bản cần phân loại,\ntokenize và id của từng class vô hàm predict của model để thực hiện dự đoán kết quả","metadata":{"id":"IzP-nMl40u7O"}},{"cell_type":"code","source":"# Tải model Mamba từ model đã được train trước đó.\nmodel = MambaTextClassification . from_pretrained (\" trinhxuankhai\\\nmamba_text_classification \")\nmodel . to (\" cuda \")\n\n# Tải tokenizer của model Mamba từ model đã được train trước đó.\ntokenizer = AutoTokenizer . from_pretrained (\" trinhxuankhai \\\nmamba_text_classification \")\n# Đặt id của token pad bằng id của token eos trong tokenizer .\ntokenizer . pad_token_id = tokenizer . eos_token_id","metadata":{"id":"K7qgDSbkQ8d2","execution":{"iopub.status.busy":"2024-03-26T19:43:59.861068Z","iopub.status.idle":"2024-03-26T19:43:59.861450Z","shell.execute_reply.started":"2024-03-26T19:43:59.861261Z","shell.execute_reply":"2024-03-26T19:43:59.861276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\ntext = imdb['test'][0]['text']\nlabel = imdb['test'][0]['label']\nresponse = model.predict(text, tokenizer, id2label)\nprint(f'Classify: {text}\\nGT: {id2label[label]}\\nPredict: {response}')\n","metadata":{"id":"T7CBRahyQ9SP","execution":{"iopub.status.busy":"2024-03-26T19:43:59.863123Z","iopub.status.idle":"2024-03-26T19:43:59.863542Z","shell.execute_reply.started":"2024-03-26T19:43:59.863343Z","shell.execute_reply":"2024-03-26T19:43:59.863360Z"},"trusted":true},"execution_count":null,"outputs":[]}]}